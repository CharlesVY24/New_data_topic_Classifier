{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f7c34f37",
   "metadata": {},
   "source": [
    "This file Contains  the data request to the API.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e281400",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install sodapy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c26043b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sodapy import Socrata\n",
    "\n",
    "import pandas as pd\n",
    "from sodapy import Socrata\n",
    "\n",
    "client = Socrata(\"www.datos.gov.co\",\n",
    "                  \"tcU2fieqxe5EiHJE2OcqmSrPq\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9becbaa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Define dataset and base query (without LIMIT or OFFSET)\n",
    "socrata_dataset_identifier = \"jbjy-vk9h\"\n",
    "\n",
    "base_query = \"\"\"\n",
    "select\n",
    "presupuesto_general_de_la_nacion_pgn,\n",
    "recursos_propios_alcald_as_gobernaciones_y_resguardos_ind_genas_,\n",
    "fecha_inicio_liquidacion,\n",
    "fecha_fin_liquidacion,\n",
    "objeto_del_contrato,\n",
    "duraci_n_del_contrato,\n",
    "urlproceso,\n",
    "nombre_representante_legal,\n",
    "origen_de_los_recursos,\n",
    "liquidaci_n,\n",
    "valor_del_contrato,\n",
    "valor_facturado,\n",
    "es_pyme,\n",
    "proveedor_adjudicado,\n",
    "fecha_de_fin_de_ejecucion,\n",
    "fecha_de_inicio_de_ejecucion,\n",
    "fecha_de_fin_del_contrato,\n",
    "fecha_de_inicio_del_contrato,\n",
    "fecha_de_firma,\n",
    "modalidad_de_contratacion,\n",
    "tipo_de_contrato,\n",
    "codigo_de_categoria_principal,\n",
    "descripcion_del_proceso,\n",
    "estado_contrato,\n",
    "referencia_del_contrato,\n",
    "id_contrato,\n",
    "proceso_de_compra,\n",
    "entidad_centralizada,\n",
    "rama,\n",
    "sector,\n",
    "orden,\n",
    "localizaci_n,\n",
    "ciudad,\n",
    "departamento,\n",
    "nit_entidad,\n",
    "nombre_entidad\n",
    "where\n",
    "    fecha_de_firma >= '2024-01-01' AND fecha_de_firma < '2024-01-31'\n",
    "    and estado_contrato not in ('En aprobaciÃ³n','enviado Proveedor','Borrador','Cancelado')\n",
    "order by fecha_de_firma desc\n",
    "\"\"\"\n",
    "\n",
    "contratos_2024 = client.get(socrata_dataset_identifier, content_type=\"json\", query=base_query)\n",
    "\n",
    "df_contratos = pd.DataFrame(pd.DataFrame.from_dict(contratos_2024))\n",
    "df_contratos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4c8c0ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Changing the datatypes\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Assuming df_contratos is your DataFrame\n",
    "\n",
    "# 1. List all text/string columns\n",
    "text_columns = [\n",
    "    'objeto_del_contrato',\n",
    "    'duraci_n_del_contrato',\n",
    "    'urlproceso',\n",
    "    'nombre_representante_legal',\n",
    "    'origen_de_los_recursos',\n",
    "    'liquidaci_n',\n",
    "    'es_pyme',\n",
    "    'proveedor_adjudicado',\n",
    "    'modalidad_de_contratacion',\n",
    "    'tipo_de_contrato',\n",
    "    'codigo_de_categoria_principal',\n",
    "    'descripcion_del_proceso',\n",
    "    'estado_contrato',\n",
    "    'referencia_del_contrato',\n",
    "    'id_contrato',\n",
    "    'proceso_de_compra',\n",
    "    'entidad_centralizada',\n",
    "    'rama',\n",
    "    'sector',\n",
    "    'orden',\n",
    "    'localizaci_n',\n",
    "    'ciudad',\n",
    "    'departamento',\n",
    "    'nit_entidad',\n",
    "    'nombre_entidad'\n",
    "]\n",
    "\n",
    "# 2. List all numeric (float) columns\n",
    "numeric_columns = [\n",
    "    'presupuesto_general_de_la_nacion_pgn',\n",
    "    'recursos_propios_alcald_as_gobernaciones_y_resguardos_ind_genas_',\n",
    "    'valor_del_contrato',\n",
    "    'valor_facturado'\n",
    "]\n",
    "\n",
    "# 3. List all date columns\n",
    "date_columns = [\n",
    "    'fecha_inicio_liquidacion',\n",
    "    'fecha_fin_liquidacion',\n",
    "    'fecha_de_fin_de_ejecucion',\n",
    "    'fecha_de_inicio_de_ejecucion',\n",
    "    'fecha_de_fin_del_contrato',\n",
    "    'fecha_de_inicio_del_contrato',\n",
    "    'fecha_de_firma'\n",
    "]\n",
    "\n",
    "# Convert text columns to string\n",
    "for col in text_columns:\n",
    "    if col in df_contratos.columns:\n",
    "        df_contratos[col] = df_contratos[col].astype(str)\n",
    "\n",
    "# Convert numeric columns to float (handling errors)\n",
    "for col in numeric_columns:\n",
    "    if col in df_contratos.columns:\n",
    "        df_contratos[col] = pd.to_numeric(df_contratos[col], errors='coerce')\n",
    "\n",
    "# Convert date columns to datetime (handling errors)\n",
    "for col in date_columns:\n",
    "    if col in df_contratos.columns:\n",
    "        df_contratos[col] = pd.to_datetime(df_contratos[col], errors='coerce')\n",
    "\n",
    "# Show the final data types\n",
    "print(\"Final Data Types:\")\n",
    "print(df_contratos.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "644c9d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install spaCy and Spanish model\n",
    "!pip install -U spacy\n",
    "!python -m spacy download es_core_news_sm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0e23fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Cleaning, removing stop words\n",
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import spacy\n",
    "\n",
    "# Load Spanish stopwords\n",
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('spanish'))\n",
    "\n",
    "# ðŸ‘‰ Add domain-specific stopwords (based on your exploration)\n",
    "contract_stopwords = {\n",
    "    'prestacion', 'servicio', 'proceso', 'contratista', 'acuerdo', 'ejecutar',\n",
    "    'condicion', 'empresa', 'nuevo', 'institucional', 'entidad', 'area',\n",
    "    'eficaz', 'eficiente', 'municipio', 'nivel', 'centro', 'ejecuciÃ³n',\n",
    "    'prestaciÃ³n', 'objeto', 'dentro', 'requerido', 'diferente', 'poner',\n",
    "    'realizar',\n",
    "    'apoyo', 'departamental', 'contrato', 'laboral', 'actividad', 'cuenta',\n",
    "    'profesional', 'contratar', 'especializado', 'prestar', 'Ã¡rea',\n",
    "    'subproceso', 'comprometer', 'garantizar', 'requerir', 'adelantar',\n",
    "    'local', 'primero', 'conformidad', 'responsabilidad', 'efectivo',\n",
    "    'disposiciÃ³n', 'forma', 'propuesta', 'bajo', 'oportuno', 'tiempo', 'autonomÃ­a'\n",
    "}\n",
    "stop_words.update(contract_stopwords)\n",
    "\n",
    "# Load Spanish language model from spaCy\n",
    "nlp = spacy.load(\"es_core_news_sm\")\n",
    "\n",
    "# Define full cleaning function with lemmatization and entity removal\n",
    "def clean_lemma_no_entities(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)  # Remove punctuation\n",
    "    doc = nlp(text)\n",
    "    tokens = [\n",
    "        token.lemma_ for token in doc\n",
    "        if token.lemma_ not in stop_words\n",
    "        and token.ent_type_ not in (\"PER\", \"LOC\", \"ORG\")  # Named entities\n",
    "        and not token.is_punct and not token.is_space\n",
    "    ]\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "# Apply to your contract descriptions\n",
    "df =df_contratos.copy()\n",
    "df['objeto_clean_lemma'] = df['objeto_del_contrato'].apply(clean_lemma_no_entities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dcc3f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"es_core_news_sm\")\n",
    "\n",
    "def clean_and_lemmatize(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    doc = nlp(text)\n",
    "    lemmatized = [token.lemma_ for token in doc if token.lemma_ not in stop_words and not token.is_punct and not token.is_space]\n",
    "    return ' '.join(lemmatized)\n",
    "\n",
    "df['objeto_clean_lemma'] = df['objeto_del_contrato'].apply(clean_and_lemmatize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78701956",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install bertopic\n",
    "from bertopic import BERTopic\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Use a multilingual model\n",
    "embedding_model = SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2')\n",
    "\n",
    "# Create BERTopic model with custom embeddings\n",
    "topic_model = BERTopic(embedding_model=embedding_model, language=\"spanish\", verbose=True)\n",
    "\n",
    "docs = df['objeto_clean_lemma'].tolist()\n",
    "\n",
    "topics, probs= topic_model.fit_transform(docs)##Storing the probabilities\n",
    "topic_model.get_topic_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13bcec78",
   "metadata": {},
   "outputs": [],
   "source": [
    " !pip install umap-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb80a71d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import umap\n",
    "from bertopic import BERTopic\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "embedding_model = SentenceTransformer(\"paraphrase-multilingual-MiniLM-L12-v2\")\n",
    "docs = df['objeto_clean_lemma'].tolist()\n",
    "embeddings = embedding_model.encode(docs, show_progress_bar=True)\n",
    "\n",
    "n_neighbors_values = [5, 15, 30, 50]  # Try different levels of locality\n",
    "results = []\n",
    "\n",
    "for n in n_neighbors_values:\n",
    "    umap_model = umap.UMAP(n_neighbors=n, min_dist=0.5, random_state=42)\n",
    "    topic_model = BERTopic(\n",
    "        embedding_model=embedding_model,\n",
    "        umap_model=umap_model,\n",
    "        language=\"spanish\",\n",
    "        verbose=False\n",
    "    )\n",
    "\n",
    "    topics, _ = topic_model.fit_transform(docs, embeddings)\n",
    "    n_topics = len(set(topics)) - (1 if -1 in topics else 0)\n",
    "    results.append((n, n_topics))\n",
    "    print(f\"n_neighbors={n} â†’ {n_topics} topics\")\n",
    "\n",
    "import umap\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "n_neighbors_list = [2, 5, 10, 15, 20, 30, 50, 100, 150]\n",
    "min_dist_fixed = 0.5\n",
    "\n",
    "fig, axes = plt.subplots(3, 3, figsize=(12, 12))\n",
    "fig.suptitle(\"UMAP - Varying n_neighbors (min_dist=0.5)\", fontsize=16)\n",
    "\n",
    "for i, n in enumerate(n_neighbors_list):\n",
    "    reducer = umap.UMAP(n_neighbors=n, min_dist=min_dist_fixed, random_state=42)\n",
    "    umap_result = reducer.fit_transform(embeddings)\n",
    "\n",
    "    row, col = divmod(i, 3)\n",
    "    ax = axes[row][col]\n",
    "    ax.scatter(umap_result[:, 0], umap_result[:, 1], s=10)\n",
    "    ax.set_title(f\"n={n}\")\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f02df97",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_dist_values = [0.0, 0.1, 0.3, 0.5, 0.8]\n",
    "results_min_dist = []\n",
    "\n",
    "for d in min_dist_values:\n",
    "    umap_model = umap.UMAP(n_neighbors=2, min_dist=d, random_state=42)\n",
    "    topic_model = BERTopic(\n",
    "        embedding_model=embedding_model,\n",
    "        umap_model=umap_model,\n",
    "        language=\"spanish\",\n",
    "        verbose=False\n",
    "    )\n",
    "\n",
    "    topics, _ = topic_model.fit_transform(docs, embeddings)\n",
    "    n_topics = len(set(topics)) - (1 if -1 in topics else 0)\n",
    "    results_min_dist.append((d, n_topics))\n",
    "    print(f\"min_dist={d} â†’ {n_topics} topics\")\n",
    "\n",
    "    min_dist_list = [0.0, 0.1, 0.3, 0.5, 0.7, 0.9, 0.99]\n",
    "n_neighbors_fixed = 15\n",
    "\n",
    "fig, axes = plt.subplots(2, 4, figsize=(16, 8))\n",
    "fig.suptitle(\"UMAP - Varying min_dist (n_neighbors=10)\", fontsize=16)\n",
    "\n",
    "for i, d in enumerate(min_dist_list):\n",
    "    reducer = umap.UMAP(n_neighbors=n_neighbors_fixed, min_dist=d, random_state=42)\n",
    "    umap_result = reducer.fit_transform(embeddings)\n",
    "\n",
    "    row, col = divmod(i, 4)\n",
    "    ax = axes[row][col]\n",
    "    ax.scatter(umap_result[:, 0], umap_result[:, 1], s=10)\n",
    "    ax.set_title(f\"min_dist={d}\")\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e83d53c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot n_neighbors results\n",
    "x, y = zip(*results)\n",
    "plt.figure()\n",
    "plt.plot(x, y, marker='o')\n",
    "plt.title(\"Effect of n_neighbors on Number of Topics\")\n",
    "plt.xlabel(\"n_neighbors\")\n",
    "plt.ylabel(\"Number of Topics\")\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Plot min_dist results\n",
    "x2, y2 = zip(*results_min_dist)\n",
    "plt.figure()\n",
    "plt.plot(x2, y2, marker='o', color='orange')\n",
    "plt.title(\"Effect of min_dist on Number of Topics\")\n",
    "plt.xlabel(\"min_dist\")\n",
    "plt.ylabel(\"Number of Topics\")\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "import umap\n",
    "\n",
    "final_umap = umap.UMAP(n_neighbors=10, min_dist=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c1e2886",
   "metadata": {},
   "outputs": [],
   "source": [
    "import umap\n",
    "from hdbscan import HDBSCAN\n",
    "from bertopic import BERTopic\n",
    "\n",
    "hdbscan_model = HDBSCAN(\n",
    "    min_cluster_size=10,         # allow smaller topics\n",
    "    min_samples=3,               # be tolerant with outliers\n",
    "    prediction_data=True,\n",
    "    cluster_selection_method='leaf'  # allow finer subclusters\n",
    ")\n",
    "\n",
    "topic_model = BERTopic(\n",
    "    embedding_model=embedding_model,\n",
    "    umap_model=final_umap,       # your best UMAP config\n",
    "    hdbscan_model=hdbscan_model,\n",
    "    language=\"spanish\",\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "topics, probs = topic_model.fit_transform(docs, embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79eb98f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "num_outliers = np.sum(np.array(topics) == -1)\n",
    "total = len(topics)\n",
    "print(f\"Outlier rate: {num_outliers}/{total} â†’ {num_outliers / total:.2%}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8129125d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['topic_id'] = topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9009f4cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Adding most representative keywords\n",
    "\n",
    "topic_info = topic_model.get_topic_info()\n",
    "topic_labels = {\n",
    "    row['Topic']: row['Name'] for _, row in topic_info.iterrows()\n",
    "}\n",
    "df['topic_label'] = df['topic_id'].map(topic_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dcc6e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['topic_label'].value_counts().plot(kind='bar', figsize=(10, 5), title=\"Contract Categories (BERTopic)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "737d79cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(['ciudad', 'topic_label']).size().unstack(fill_value=0).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbbf3734",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_excel(\"contratos_categorizados_bertopic_Unlimited.xlsx\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
